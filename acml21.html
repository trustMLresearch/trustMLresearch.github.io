<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>ACML2021 WSL Workshop</title>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href="./style.css">
  </head>
 

<script type="text/javascript">
var myDate = "2021-11-17T"
var myStartTime = "09:00"
var myTimeZone = "+07:00"

var myStartTime = new Date(myDate + myStartTime + ":00.000" + myTimeZone);
var myRefTime = new Date(myDate + "00:00:00.000" + myTimeZone);

function getTimezone() {
  var offset = -(new Date()).getTimezoneOffset()/60;
  return ("UTC" + (offset >= 0 ? "+" : "") + offset);
}

function getLocalTimezone() {
  try {
    return Intl.DateTimeFormat().resolvedOptions().timeZone + " time (" + getTimezone() + ", your browser's time zone)";
  }
  catch(e) {
    return " (" + getTimezone() + ", i.e., your browser's time zone)";
  }
}

function displayTime(dt) {
  var hour = dt.getHours();
  var minute = dt.getMinutes();
  var temp = '' + ((hour < 10) ? '0' : '') + hour;
  temp += ((minute < 10) ? ':0' : ':') + minute;
  return temp;
}

function writeTimeRange(startHour, startMin, endHour, endMin) {
  var oneMin = 1000 * 60;
  var oneHour = oneMin * 60;
  var startTime = new Date(myRefTime.getTime() + startHour * oneHour + startMin * oneMin);
  var endTime = new Date(myRefTime.getTime() + endHour * oneHour + endMin * oneMin);
  document.write(displayTime(startTime));
  document.write(" -- ");
  document.write(displayTime(endTime));
  if (endTime.getDay() != myStartTime.getDay()) {
    document.write(" (next day)");
  }
  return;
}
</script>


 <body>
    <section class="page-header">
      <h1 class="project-name">ACML2021 WSL Workshop</h1>
      <h2 class="project-tagline">Weakly Supervised Learning Workshop, 9:30 -- 12:10 Nov. 17th, 2021 (Bangkok Time), Online <br/>

      <script type="text/javascript">
        document.write("*");
        document.write(myStartTime.toLocaleDateString('en-US', {month:'short', day:'numeric'}));
        document.write(" ");
        writeTimeRange(09, 30, 12, 10);
        document.write(" ");
        document.write(getLocalTimezone())
        </script>
      </h2>
    </section>

<section class="main-content">
    <center>[ <a href="#topics">Topics</a>,
         <a href="#submission">Participation</a>,
         <a href="#program">Program</a>,
         <a href="#organizers">Organizers</a>,
         <a href="#previous-workshops">Previous Workshops</a> ]</center>
         
<h1 id="topics">Topics</h1>

    <h2>Overview</h2>
        <p>Machine learning should not be accessible only to those who can pay. Specifically, modern machine learning is migrating to the era of complex models (e.g., deep neural networks), which require a plethora of well-annotated data. Giant companies have enough money to collect well-annotated data. However, for startups or non-profit organizations, such data is barely acquirable due to the cost of labeling data or the intrinsic scarcity in the given domain. These practical issues motivate us to research and pay attention to <b>weakly supervised learning (WSL)</b>, since WSL does not require such a huge amount of annotated data. We define WSL as the collection of machine learning problem settings and algorithms that share the same goals as supervised learning but can only access to <b>less supervised information</b> than supervised learning. In this workshop, we discuss both theoretical and applied aspects of WSL.</p>

        <p>This workshop is a series of our previous workshops at ACML 2019, SDM 2020, ACML 2020, and IJCAI 2021. Our particular emphasis at this workshop is incomplete supervision, inexact supervision, inaccurate supervision, cross-domain supervision, imperfect demonstration, and <font color="#FF0000">weak adversarial supervision (new topic)</font>.</p>

    <h2>Topics of Interest</h2>
        <p>WSL workshop includes (but not limited to) the following topics:</p>
        <ul>
            <li>Algorithms and theories of <b>incomplete supervision</b>, e.g., semi-supervised learning, active learning and positive-unlabeled learning;</li>
            <li>Algorithms and theories of <b>inexact supervision</b>, e.g., multi-instance learning and complementary learning;</li>
            <li>Algorithms and theories of <b>inaccurate supervision</b>, e.g., crowdsourced learning and label-noise learning;</li>
            <li>Algorithms and theories of <b>cross-domain supervision</b>, e.g., zero-/one-/few-shot learning, transferable learning and multi-task leaning;</li>
            <li>Algorithms and theories of <b>imperfect demonstration</b>, e.g., inverse reinforcement learning and imitation learning with non-expert demonstrations;</li>
            <li>Algorithms and theories of <b>adversarial</b> weakly-supervised learning, e.g., adversarial semi-supervised learning and adversarial contrastive learning and adversarial label-noisy learning; </li>
            <li>Broad applications of weakly supervised learning, such as weakly supervised <b>object detection</b>, weakly supervised <b>sequence modeling</b>, weakly supervised <b>cross-media retrieval</b>, and weakly supervised <b>medical image segmentation</b>.</li>
        </ul>

    <h2>Further Descriptions</h2>
        <p>The focus of this workshop is six types of weak supervision: incomplete supervision, inexact supervision, inaccurate supervision, cross-domain supervision, imperfect demonstration, and weak adversarial supervision. 
        Specifically, incomplete supervision considers a subset of training data given with ground-truth labels while the other data remain unlabeled, such as semi-supervised learning and positive-unlabeled learning. 
        Inexact supervision considers the situation where some supervision information is given but not as exacted as desired, i.e., only coarse-grained labels are available. For example, if we are considering to classify every pixel of an image, rather than the image itself, then ImageNet becomes a benchmark with inexact supervision. Besides, multi-instance learning belongs to inexact supervision, where we do not exactly know which instance in the bag corresponds to the given ground-truth label. 
        Inaccurate supervision considers the situation where the supervision information is not always the ground-truth, such as label-noise learning.</p>

        <p>Cross-domain supervision considers the situation where the supervision information is scarce or even non-existent
        in the current domain but can be possibly derived from other domains. Examples of cross-domain supervision appear in zero-/one-/few-shot learning, where external knowledge from other domains is usually used to overcome the problem of too few or even no supervision in the original domain. 

        Imperfect demonstration considers the situation for inverse reinforcement learning and imitation learning, where the agent learns with imperfect or non-expert demonstrations. For example, AlphaGo learns a policy from a sequence of states and actions (expert demonstration). Even if an expert player wins a game, it is not guaranteed that every action in the sequence is optimal.</p>

        <p>Weak adversarial supervision considers the situation where weak supervision meets adversarial robustness. 
        Since ML models are increasingly deployed in real-world applications, AI security attracts more and more attention from both academia and industry. Therefore, many robust learning algorithms aim to prevent various evasion attacks, e.g., adversarial attacks, privacy attacks, model stealing attacks, and so on. 
        However, almost all those robust algorithms (against evasion attacks) implicitly assume the strong supervision signals, which hardly meets the requirements in practice. For example, almost all adversarial training algorithms assume the labels of training data are clean without any noisy labels, which is not true in practice even in the example of benchmark datasets like CIFAR-10 and MNIST. 
        Therefore, when we develop evasion-robust algorithms, it is very practical/urgent to consider the supervision signals are imperfect. 
        </p>

        <p>This workshop will discuss the fundamental theory of weakly supervised learning. Although theories of weakly supervised statistical learning already exist, extending these results for weakly supervised learning is still a challenge. Besides, this workshop also discusses on broad applications of weakly supervised learning, such as weakly supervised object detection (computer vision), weakly supervised sequence modeling (natural language processing), weakly supervised cross-media retrieval (information retrieval), and weakly supervised medical image segmentation (healthcare analysis).</p>

<h1 id="submission">Participation</h1>
    <p>There are no paper submissions in this workshop. We sincerely welcome anyone to participate in this workshop.</p>

    <P>Topic: ACML2021 Weakly Supervised Learning Workshop </p>
    <p>Time: Nov 17, 2021 09:30 AM Bangkok (Online) </p>



<h1 id="program">Program</h1>
    
    <h2>Invited Speakers</h2>
        
        <p><a href="https://zhouchenlin.github.io/">Zhouchen Lin</a>, Peking University, China</p>
        <p><a href="https://personal.ntu.edu.sg/hanwangzhang/">Hanwang Zhang</a>, Nanyang Technological University, Singapore</p>
        <p><a href="http://boqinggong.info"> Boqing Gong</a>, Research Scientist Google, US</p>

    <h2>Schedule</h1>
        <p>The workshop will use <a href="https://time.is/GMT+7">GMT+7</a> for scheduling, and it will be combined with keynote talks, contributed talks, and panel discussions. *Corresponds to Beijing/Singapore Time from 10:30am - 1:10pm; Corresponds to Tokyo Time from 11:30am - 2:10pm; Corresponds to Los Angeles Time (previous day) from 7:30pm-10:10pm</p>

        <table>
          <thead>
            <tr>
              <th>Time (GMT+7)</th>
              <th>Event</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td>9:30-9:35am</td>
              <td><b>Opening Ceremony</b></td>
            </tr>
            <tr>
              <td>&nbsp;</td>
              <td><b>Host</b>: <a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">Masashi Sugiyama</a></td>
            </tr>
            <tr>
              <td>09:35-10:10am</td>
              <td><b>Keynote Talk 1</b></td>
            </tr>

            <tr>
              <td>&nbsp;</td>
              <td><b>Title</b>: Self-Supervised Learning Disentangled Group Representation as Feature</td>
            </tr>
            <tr>
              <td>&nbsp;</td>
                <td><b>Speaker</b>: <a href="https://personal.ntu.edu.sg/hanwangzhang/">Hanwang Zhang</a></td>
            </tr>


            <tr>
              <td>10:10-10:50am</td>
              <td><b>Contributed talks</b></td>
            </tr>
            <tr>
              <td>&nbsp;</td>
              <td><b>Title</b>: Is Complementary Label Learning a Very Difficult Task? (by <a href="https://dengbaowang.github.io">Deng-Bao Wang</a>)</td>
            </tr>
           <tr>
              <td>&nbsp;</td>
              <td><b>Title</b>: Graph Poisson Networks: Semi-Supervised Learning with Extremely Limited Labels (by <a href="https://ieeexplore.ieee.org/author/37088382481">Sheng Wan</a>)</td>
            </tr>
           <tr>
              <td>&nbsp;</td>
              <td><b>Title</b>: Learning with Noisy Labels Revisited: A Study Using Real-world Human Annotations (by <a href="https://sites.google.com/brown.edu/jiahengwei97">Jiaheng Wei</a>)</td>
            </tr>
           <tr>
            <tr>
              <td>&nbsp;</td>
              <td><b>Title</b>: Taming Overconfident Predictions on Unlabelled data from Hindsight (by <a href="https://kylejingli.github.io">Jing Li</a>)</td>
            </tr>
           <tr>

            <tr>
              <td>10:50-11:30am</td>
              <td><b>Keynote Talk 2</b></td>
            </tr>

            <tr>
              <td>&nbsp;</td>
              <td><b>Title</b>: Label-Efficient Learning of Vision Transformer</td>
            </tr>
            <tr>
              <td>&nbsp;</td>
                <td><b>Speaker</b>: <a href="http://boqinggong.info"> Boqing Gong</a></td>
            </tr>
           
            <tr>
              <td>11:30-12:10pm</td>
              <td><b>Keynote Talk 3</b></td>
            </tr>

            <tr>
              <td>&nbsp;</td>
              <td><b>Title</b>: Leveraged Weighted Loss for Partial Label Learning</td>
            </tr>
            <tr>
              <td>&nbsp;</td>
                <td><b>Speaker</b>: <a href="https://zhouchenlin.github.io/">Zhouchen Lin</a></td>
            </tr>
            
            <tr>
              <td>12:10pm</td>
              <td><b>Concluding Remark</b></td>
            </tr>
            <tr>
              <td>&nbsp;</td>
              <td><b>Host</b>: <a href="https://zjfheart.github.io/">Jingfeng Zhang</a></td>
            </tr>
          </tbody>
        </table>

<h1 id="organizers">Organizers</h1>

    <h2>Program Co-chairs</h1>
        <p><a href="https://zjfheart.github.io/">Jingfeng Zhang</a>, RIKEN, Japan.</p>
        <p><a href="https://fengliu90.github.io/">Feng Liu</a>, The University of Technology Sydney, Australia.</p>
        <p><a href="https://scholar.google.co.jp/citations?user=KQUQlG4AAAAJ&hl=en">Nan Lu</a>, The University of Tokyo, Japan.</p>
        <p><a href="https://lfeng-ntu.github.io/">Lei Feng</a>, Chongqing University, China.</p>
        <p><a href="https://tongliang-liu.github.io/">Tongliang Liu</a>, The University of Sydney, Australia.</p>
        <p><a href="https://bhanml.github.io/">Bo Han</a>, Hong Kong Baptist University, Hong Kong SAR, China.</p>
        <p><a href="https://niug1984.github.io/">Gang Niu</a>, RIKEN, Japan.</p>
        <p><a href="http://www.ms.k.u-tokyo.ac.jp/sugi/">Masashi Sugiyama</a>, RIKEN / University of Tokyo, Japan.</p>

    <h2>Advisory Board <span style="font-size: 75%">(alphabetical order by last name)</span></h1>
        <p><a href="https://gcatnjust.github.io/ChenGong/index.html">Chen Gong</a>, Nanjing University of Science and Technology, China.</p>
        <p><a href="https://mingming-gong.github.io/">Mingming Gong</a>, The University of Melbourne, Australia.</p>
        <p><a href="http://www.yliuu.com/">Yang Liu</a>, University of California, Santa Cruz, US.</p>
        <p><a href="https://www.uts.edu.au/staff/ivor.tsang">Ivor W. Tsang</a>, University of Technology Sydney, Australia.</p>
        <p><a href="https://sites.google.com/site/csyisenwang/">Yisen Wang</a>, Peking University, China.</p>
        <p><a href="https://miaoxu-ml.github.io/index.html">Miao Xu</a>, The University of Queensland, Australia.</p>
        <p><a href="http://www.cse.ust.hk/~qyaoaa/">Quanming Yao</a>, Tsinghua University / 4Paradigm Inc., China.</p>
        <p><a href="http://palm.seu.edu.cn/zhangml/">Min-Ling Zhang</a>, Southeast University, China.</p>

<h1 id="previous-workshops">Previous Workshops</h1>
    <p><a href="https://wsl-workshop.github.io/ijcai21.html">IJCAI2021 WSRL Workshop</a>, Online.</p> 
    <p><a href="https://wsl-workshop.github.io/acml20.html">ACML2020 WSRL Workshop</a>, Online.</p>
    <p><a href="https://wsl-workshop.github.io/sdm20.html">SDM2020 WSUL Workshop</a>, Ohio, United States.</p>
    <p><a href="https://wsl-workshop.github.io/acml19.html">ACML2019 WSL Workshop</a>, Nagoya, Japan.</p>

<footer class="site-footer">
    <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com/">GitHub Pages</a>.</span>
</footer>
</section>
</body></html>
